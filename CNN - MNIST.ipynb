{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c2841f",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ba7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc0199",
   "metadata": {},
   "source": [
    "### Defining some constants/hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053002e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65b302",
   "metadata": {},
   "source": [
    "### Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b5239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab350ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the train and test dataset\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c73a027",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b0bb48",
   "metadata": {},
   "source": [
    "### Scaling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c0ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a78ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086e04d",
   "metadata": {},
   "source": [
    "### Defining the set sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a17d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set size\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44b3a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set size\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db94828",
   "metadata": {},
   "source": [
    "### Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d98fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed767d",
   "metadata": {},
   "source": [
    "### Splitting the train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761efec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "\n",
    "# Validation data\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66485b50",
   "metadata": {},
   "source": [
    "### Batching the data\n",
    "#### NOTE: For proper functioning of the model, we need to create one big batch for the validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16197c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "# Test data\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "# Validation test\n",
    "validation_data = validation_data.batch(num_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121aa7d7",
   "metadata": {},
   "source": [
    "# Creating the model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1c529",
   "metadata": {},
   "source": [
    "### Outlining the model / Architecture of our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330fba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e195b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A brief summary of the model and parameters\n",
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25a4ef",
   "metadata": {},
   "source": [
    "### Defining the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fcd80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of incorporating the softmax into the model itself, we use\n",
    "# a loss calculation that automatically corrects for the missing softmax\n",
    "\n",
    "# from_logits = True -> this tells tensorflow to incorporate softmax into the loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd2c47",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6ee067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will combine the model with de loss function and optimizer, and will prepare our network for training\n",
    "model.compile(optimizer='adam', loss = loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f272472",
   "metadata": {},
   "source": [
    "### Defining an early-stopping mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01afc3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ddd6e",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a9b7340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 16s - loss: 0.2719 - accuracy: 0.9226 - val_loss: 0.0779 - val_accuracy: 0.9762 - 16s/epoch - 37ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 17s - loss: 0.0697 - accuracy: 0.9787 - val_loss: 0.0577 - val_accuracy: 0.9815 - 17s/epoch - 41ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 16s - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.0435 - val_accuracy: 0.9875 - 16s/epoch - 37ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 21s - loss: 0.0442 - accuracy: 0.9863 - val_loss: 0.0396 - val_accuracy: 0.9872 - 21s/epoch - 50ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 21s - loss: 0.0364 - accuracy: 0.9891 - val_loss: 0.0302 - val_accuracy: 0.9908 - 21s/epoch - 49ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 15s - loss: 0.0319 - accuracy: 0.9906 - val_loss: 0.0269 - val_accuracy: 0.9918 - 15s/epoch - 35ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 15s - loss: 0.0287 - accuracy: 0.9911 - val_loss: 0.0158 - val_accuracy: 0.9953 - 15s/epoch - 36ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 15s - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0197 - val_accuracy: 0.9943 - 15s/epoch - 35ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 15s - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0130 - val_accuracy: 0.9953 - 15s/epoch - 36ms/step\n",
      "Epoch 10/20\n",
      "422/422 - 15s - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0147 - val_accuracy: 0.9950 - 15s/epoch - 36ms/step\n",
      "Epoch 11/20\n",
      "422/422 - 15s - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0149 - val_accuracy: 0.9960 - 15s/epoch - 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa821f79d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data = validation_data,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0232c",
   "metadata": {},
   "source": [
    "# Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d882b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0364 - accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8c271d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.0364. Test acuraccy:  98.87%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0: .4f}. Test acuraccy: {1: .2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
